{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# ---------------\n",
    "# Author : Debanjan Datta\n",
    "# Email : ddatta@vt.edu\n",
    "# ---------------\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('./../..')\n",
    "sys.path.append('./..')\n",
    "from time import time\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pandarallel.initialize()\n",
    "\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import RandomSampler, SequentialSampler\n",
    "import yaml\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from torch import FloatTensor as FT\n",
    "from torch import LongTensor as LT\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Device ::  cuda:0\n",
      "Cuda available :: True Cuda current device :: 0 Tesla P100-PCIE-16GB\n",
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      " Input ::  torch.Size([16, 10])\n",
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        dev = \"cuda:0\"\n",
    "    else:\n",
    "        dev = \"cpu\"\n",
    "\n",
    "    DEVICE = torch.device(dev)\n",
    "    print('Set Device :: ', DEVICE)\n",
    "    print('Cuda available ::', torch.cuda.is_available(),\n",
    "          'Cuda current device ::', torch.cuda.current_device(),\n",
    "          torch.cuda.get_device_name(0))\n",
    "except:\n",
    "    print('No CUDA')\n",
    "\n",
    "try:\n",
    "    from torch import has_cudnn\n",
    "\n",
    "    if has_cudnn:\n",
    "        torch.cudnn.benchmark = False\n",
    "        print('Set cudnn benchmark to True')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from .gam_module import agreement_net_v2 as gam_net\n",
    "    from .gam_module import gam_loss\n",
    "    from .clf_net import clf_net_v2 as clf_MLP\n",
    "    from .clf_net import clf_loss as clf_loss\n",
    "    from .record_node import graph_net_v2 as graph_net\n",
    "    from .torch_data_loader import type1_Dataset\n",
    "    from .torch_data_loader import dataGeneratorWrapper\n",
    "    from . import train_utils\n",
    "    from .torch_data_loader import pairDataGenerator_v1\n",
    "    from .torch_data_loader import singleDataGenerator\n",
    "    from .torch_data_loader import pairDataGenerator_v2\n",
    "    from .src.Classifiers import wide_n_deep_model as clf_WIDE_N_DEEP\n",
    "    from .src.Classifiers import deepFM  as clf_DEEP_FM\n",
    "except:\n",
    "    from gam_module import agreement_net_v2 as gam_net\n",
    "    from gam_module import gam_loss\n",
    "    from clf_net import clf_net_v2 as clf_MLP\n",
    "    from clf_net import clf_loss as clf_loss\n",
    "    from record_node import graph_net_v2 as graph_net\n",
    "    from torch_data_loader import type1_Dataset\n",
    "    from torch_data_loader import pairDataGenerator_v1\n",
    "    from torch_data_loader import pairDataGenerator_v2\n",
    "    from torch_data_loader import singleDataGenerator\n",
    "    from src.Classifiers import wide_n_deep_model as clf_WIDE_N_DEEP\n",
    "    from src.Classifiers import deepFM  as clf_DEEP_FM\n",
    "    from torch_data_loader import singleDataGenerator\n",
    "    \n",
    "    \n",
    "    \n",
    "import train_utils\n",
    "import data_preprocess\n",
    "from GAM_SS_module import SS_network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================== #\n",
    "\n",
    "config_file = 'config.yaml'\n",
    "CONFIG = None\n",
    "DATA_SOURCE_DIR_1 = None\n",
    "DATA_SOURCE_DIR_2 = None\n",
    "model_use_data_DIR = None\n",
    "DIR = None\n",
    "logger = None\n",
    "Logging_Dir = None\n",
    "domain_dims = None\n",
    "score_col = 'score'\n",
    "fraud_col = 'fraud'\n",
    "anomaly_col = 'anomaly'\n",
    "id_col = 'PanjivaRecordID'\n",
    "label_col = 'y'\n",
    "true_label_col = 'y_true'\n",
    "node_emb_dim = 128\n",
    "feature_col_list = []\n",
    "serial_mapping_df = None\n",
    "is_labelled_col = 'labelled'\n",
    "matrix_node_emb_path = None\n",
    "confidence_bound = 0.2\n",
    "epochs_f = 0\n",
    "epochs_g = 0\n",
    "log_interval_f = 10\n",
    "log_interval_g = 10\n",
    "max_IC_iter = 5\n",
    "clf_mlp_layer_dimesnions = []\n",
    "gam_encoder_dimensions_mlp = []\n",
    "batch_size_g = 128\n",
    "batch_size_f = 128\n",
    "batch_size_r = 128\n",
    "F_classifier_type = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def setup_config(_DIR):\n",
    "    global CONFIG\n",
    "    global config_file\n",
    "    global DATA_SOURCE_DIR_1\n",
    "    global DATA_SOURCE_DIR_2\n",
    "    global DIR\n",
    "    global Logging_Dir\n",
    "    global model_use_data_DIR\n",
    "    global domain_dims\n",
    "    global feature_col_list\n",
    "    global serial_mapping_df\n",
    "    global serialized_feature_col_list\n",
    "    global matrix_node_emb_path\n",
    "    global confidence_bound\n",
    "    global epochs_f\n",
    "    global epochs_g\n",
    "    global log_interval_f\n",
    "    global log_interval_g\n",
    "    global max_IC_iter\n",
    "    global clf_mlp_layer_dimesnions\n",
    "    global gam_encoder_dimensions_mlp\n",
    "    global batch_size_g\n",
    "    global batch_size_f\n",
    "    global batch_size_r\n",
    "    global F_classifier_type\n",
    "\n",
    "    if _DIR is not None:\n",
    "        DIR = _DIR\n",
    "\n",
    "    with open(config_file) as f:\n",
    "        CONFIG = yaml.safe_load(f)\n",
    "        \n",
    "    F_classifier_type = CONFIG['clf_type']\n",
    "    DATA_SOURCE_DIR_1 = CONFIG['DATA_SOURCE_DIR_1']\n",
    "    DATA_SOURCE_DIR_2 = CONFIG['DATA_SOURCE_DIR_2']\n",
    "\n",
    "    DATA_SOURCE_DIR_1 = os.path.join(DATA_SOURCE_DIR_1, DIR)\n",
    "    DATA_SOURCE_DIR_2 = os.path.join(DATA_SOURCE_DIR_2, DIR)\n",
    "\n",
    "    model_use_data_DIR = CONFIG['model_use_data_DIR']\n",
    "    if not os.path.exists(model_use_data_DIR): os.mkdir(model_use_data_DIR)\n",
    "    model_use_data_DIR = os.path.join(model_use_data_DIR, DIR)\n",
    "    if not os.path.exists(model_use_data_DIR): os.mkdir(model_use_data_DIR)\n",
    "\n",
    "    with open(\n",
    "            os.path.join(\n",
    "                DATA_SOURCE_DIR_1,\n",
    "                'domain_dims.pkl'\n",
    "            ), 'rb') as fh:\n",
    "        domain_dims = pickle.load(fh)\n",
    "\n",
    "    feature_col_list = list(sorted(domain_dims.keys()))\n",
    "    serialized_feature_col_list = ['_' + _ for _ in feature_col_list]\n",
    "    serial_mapping_df_path = os.path.join(\n",
    "        CONFIG['serial_mapping_df_loc'],\n",
    "        DIR,\n",
    "        CONFIG['serial_mapping_df_name']\n",
    "    )\n",
    "    serial_mapping_df = pd.read_csv(serial_mapping_df_path, index_col=None)\n",
    "    matrix_node_emb_path = os.path.join(CONFIG['matrix_node_emb_loc'], DIR, CONFIG['matrix_node_emb_file'])\n",
    "    confidence_bound = CONFIG['confidence_bound']\n",
    "    epochs_g = CONFIG['epochs_g']\n",
    "    epochs_f = CONFIG['epochs_f']\n",
    "    log_interval_f = CONFIG['log_interval_f']\n",
    "    log_interval_g = CONFIG['log_interval_g']\n",
    "    max_IC_iter = CONFIG['max_IC_iter']\n",
    "    clf_mlp_layer_dimesnions = [\n",
    "        int(_)\n",
    "        for _ in CONFIG['classifier_mlp_layers_1'].split(',')\n",
    "    ]\n",
    "    gam_encoder_dimensions_mlp = [\n",
    "        int(_)\n",
    "        for _ in CONFIG['gam_encoder_dimensions_mlp'].split(',')\n",
    "    ]\n",
    "\n",
    "    batch_size_g = CONFIG['batch_size_g']\n",
    "    batch_size_f = CONFIG['batch_size_f']\n",
    "    batch_size_r = CONFIG['batch_size_r']\n",
    "    Logging_Dir = CONFIG['Logging_Dir']\n",
    "    logger = get_logger()\n",
    "    logger.info(str(datetime.utcnow()))\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "def get_logger():\n",
    "    global Logging_Dir\n",
    "    global DIR\n",
    "    logger = logging.getLogger('main')\n",
    "    logger.setLevel(logging.INFO)\n",
    "    OP_DIR = os.path.join(Logging_Dir, DIR)\n",
    "    log_file = 'results.log'\n",
    "    if not os.path.exists(Logging_Dir):\n",
    "        os.mkdir(Logging_Dir)\n",
    "\n",
    "    if not os.path.exists(OP_DIR):\n",
    "        os.mkdir(OP_DIR)\n",
    "\n",
    "    log_file_path = os.path.join(OP_DIR, log_file)\n",
    "    handler = logging.FileHandler(log_file_path)\n",
    "    handler.setLevel(logging.INFO)\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def close_logger(logger):\n",
    "    handlers = logger.handlers[:]\n",
    "    for handler in handlers:\n",
    "        handler.close()\n",
    "        logger.removeHandler(handler)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_config('us_import2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files:  model_use_data/us_import2/preprocessed_data_MLP.csv model_use_data/us_import2/features_F_MLP.dat model_use_data/us_import2/features_G_MLP.dat model_use_data/us_import2/__id_pool_MLP.dat\n"
     ]
    }
   ],
   "source": [
    "df_target, normal_data_samples_df, features_F, features_G = data_preprocess.get_data_plus_features(\n",
    "        DATA_SOURCE_DIR_1,\n",
    "        DATA_SOURCE_DIR_2,\n",
    "        model_use_data_DIR,\n",
    "        F_classifier_type,\n",
    "        domain_dims,\n",
    "        serial_mapping_df,\n",
    "        score_col,\n",
    "        is_labelled_col,\n",
    "        label_col,\n",
    "        true_label_col,\n",
    "        fraud_col,\n",
    "        anomaly_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix_node_emb (matrix_node_emb_path):\n",
    "    emb = np.load(matrix_node_emb_path)\n",
    "    return emb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def regularization_loss(\n",
    "    g_ij, \n",
    "    fi_yj\n",
    "):\n",
    "    g_ij = g_ij.view(-1)\n",
    "    val1 = (fi_yj[0] - fi_yj[1]) ** 2\n",
    "    val2 = val1.float() * g_ij\n",
    "    val3 = (val2).mean()\n",
    "    return val3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "        NN, df, normal_data_samples_df, features_F, features_G\n",
    "):\n",
    "    global epochs_f\n",
    "    global epochs_g\n",
    "    global log_interval_f\n",
    "    global log_interval_g\n",
    "    global max_IC_iter\n",
    "    global serialized_feature_col_list\n",
    "    global feature_col_list\n",
    "    global DEVICE\n",
    "    global batch_size_g\n",
    "    global batch_size_f\n",
    "    global batch_size_r\n",
    "\n",
    "    num_epochs_g = epochs_g\n",
    "    num_epochs_f = epochs_f\n",
    "\n",
    "    num_proc = multiprocessing.cpu_count()\n",
    "    lambda_LL = 0.1\n",
    "    lambda_UL = 0.01\n",
    "    lambda_UU = 0.005\n",
    "\n",
    "    df_L = train_utils.extract_labelled_df(df)\n",
    "    df_U = train_utils.extract_unlabelled_df(df)\n",
    "    df_L = df_L.copy()\n",
    "    df_L, df_L_validation = train_utils.obtain_train_validation(\n",
    "        df_L\n",
    "    )\n",
    "    f_feature_cols = None\n",
    "    \n",
    "    # Add in normal data to validation data\n",
    "    df_L_validation = df_L_validation.append(\n",
    "        normal_data_samples_df.sample(len(df_L_validation)),\n",
    "        ignore_index=True\n",
    "    )\n",
    "    \n",
    "    df_U_original = df_U.copy()\n",
    "    print('>> Data set lengths :', len(df_L), len(df_L_validation), len(df_U))\n",
    "\n",
    "    current_iter_count = 0\n",
    "    continue_training = True\n",
    "    \n",
    "    while continue_training:\n",
    "        # GAM gets inputs as embeddings, which are obtained through the graph embeddings\n",
    "        # that requires serialized feature ids\n",
    "        g_feature_cols = serialized_feature_col_list\n",
    "\n",
    "        NN.train_mode = 'g'\n",
    "        data_source_L1 = type1_Dataset(\n",
    "            df_L,\n",
    "            x_cols=features_G,\n",
    "            y_col=label_col\n",
    "        )\n",
    "\n",
    "        dataLoader_obj_L1a = DataLoader(\n",
    "            data_source_L1,\n",
    "            batch_size=batch_size_g,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=num_proc,\n",
    "            sampler=RandomSampler(data_source_L1),\n",
    "            drop_last=True\n",
    "        )\n",
    "        dataLoader_obj_L1b = DataLoader(\n",
    "            data_source_L1,\n",
    "            batch_size=batch_size_g,\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            num_workers=num_proc,\n",
    "            sampler=RandomSampler(data_source_L1),\n",
    "            drop_last=True\n",
    "        )\n",
    "        \n",
    "        params_list_g = [_ for _ in NN.graph_net.parameters()]\n",
    "        params_list_g = params_list_g + ([_ for _ in NN.agreement_net.parameters()])\n",
    "        print('# of parameters to be optimized for g ', len(params_list_g))\n",
    "        optimizer_g = torch.optim.Adam(\n",
    "            params_list_g,\n",
    "            lr=0.015\n",
    "        )\n",
    "\n",
    "        params_list_f = [_ for _ in NN.graph_net.parameters()]\n",
    "        params_list_f = params_list_f + [_ for _ in NN.clf_net.parameters()]\n",
    "\n",
    "        print('# of parameters to be optimized for f ', len(params_list_f))\n",
    "        optimizer_f = torch.optim.Adam(\n",
    "            params_list_f,\n",
    "            lr = 0.05\n",
    "        )\n",
    "\n",
    "        final_epoch_g = False  # To check convergence\n",
    "        if NN.train_mode == 'g':\n",
    "            # ----\n",
    "            # input_x1,y2 : from Dataloader ( L )\n",
    "            # input x2,y2 : from Dataloader ( L )\n",
    "            # For every pair, so nest them\n",
    "            # -----\n",
    "            print('Training Agreement model .... ')\n",
    "            optimizer_g.zero_grad()\n",
    "            prev_loss = 0\n",
    "            iter_below_tol = 0\n",
    "            log_interval_g = 2\n",
    "            \n",
    "            for epoch in range(num_epochs_g):\n",
    "                break\n",
    "                print('Epoch [g]', epoch)\n",
    "                record_loss = []\n",
    "                batch_idx = 0\n",
    "                for i, data_i in enumerate(dataLoader_obj_L1a):\n",
    "                    if type(data_i) == list:\n",
    "                        data_i = [_.to(DEVICE) for _ in data_i]\n",
    "                    else:\n",
    "                        data_i = data_i.to(DEVICE)\n",
    "\n",
    "                    x1 = data_i[0]\n",
    "                    y1 = data_i[1]\n",
    "\n",
    "                    for j, data_j in enumerate(dataLoader_obj_L1b):\n",
    "                        if type(data_i) == list:\n",
    "                            data_j = [_.to(DEVICE) for _ in data_j]\n",
    "                        else:\n",
    "                            data_j = data_j.to(DEVICE)\n",
    "                            \n",
    "                        x2 = data_j[0]\n",
    "                        y2 = data_j[1]\n",
    "                        input_x = [x1, x2]\n",
    "\n",
    "                        true_agreement = np.array(y1 == y2).astype(float)\n",
    "                        true_agreement = np.reshape(true_agreement, [-1, 1])\n",
    "\n",
    "                        true_agreement = FT(true_agreement).to(DEVICE)\n",
    "                        pred_agreement = NN(input_x)\n",
    "\n",
    "                        loss = F.binary_cross_entropy(pred_agreement, true_agreement)\n",
    "                        loss.backward()\n",
    "\n",
    "                        optimizer_g.step()\n",
    "                        record_loss.append(float(loss))\n",
    "                        batch_idx += 1\n",
    "                        if batch_idx % log_interval_g == 0:\n",
    "                            print(\n",
    "                                'Epoch {}, Batch [g] {} :: Loss {}'.format(\n",
    "                                    epoch, batch_idx, loss)\n",
    "                            )\n",
    "                        cur_loss = loss\n",
    "                        # ------------------------\n",
    "                        # If training performance is not improving, stop training\n",
    "                        # ------------------------\n",
    "                        is_converged, iter_below_tol, = train_utils.check_convergence(\n",
    "                            prev_loss=prev_loss,\n",
    "                            cur_loss=loss,\n",
    "                            cur_step=batch_idx,\n",
    "                            iter_below_tol=iter_below_tol,\n",
    "                            abs_loss_chg_tol=0.01,\n",
    "                            min_num_iter=50,\n",
    "                            max_iter_below_tol=20\n",
    "                        )\n",
    "                        prev_loss = cur_loss\n",
    "                        if is_converged:\n",
    "                            final_epoch_g = True\n",
    "                if final_epoch_g:\n",
    "                    break\n",
    "\n",
    "        # -----------------------\n",
    "        # Train the classifier\n",
    "        # Use only labelled data\n",
    "        # ----------------------\n",
    "        # To do separate out f and g features\n",
    "\n",
    "        optimizer_f.zero_grad()\n",
    "        data_source_L2 = type1_Dataset(\n",
    "            df_L,\n",
    "            x_cols=g_feature_cols,\n",
    "            y_col=label_col\n",
    "        )\n",
    "\n",
    "        print('[[ --- Training Classifier ---- ]]')\n",
    "        optimizer_f.zero_grad()\n",
    "        \n",
    "        for epoch in range(num_epochs_f):\n",
    "            print('Epoch [f]', epoch)\n",
    "\n",
    "            data_L_generator = singleDataGenerator(\n",
    "                df_L,\n",
    "                x_cols=features_F,\n",
    "                y_col=label_col,\n",
    "                batch_size = batch_size_r\n",
    "            )\n",
    "\n",
    "            data_LL_generator = pairDataGenerator_v2(\n",
    "                    df_1=df_L,\n",
    "                    df_2=df_L,\n",
    "                    x1_F_col = features_F,\n",
    "                    x2_F_col = features_F,\n",
    "                    x1_G_col = features_G,\n",
    "                    x2_G_col = features_G,\n",
    "                    y1_col=None,\n",
    "                    y2_col=label_col,\n",
    "                    batch_size=batch_size_r,\n",
    "                    device = DEVICE,\n",
    "                    allow_refresh = True\n",
    "            )\n",
    "\n",
    "            data_UL_generator = pairDataGenerator_v2(\n",
    "                df_1=df_U,\n",
    "                df_2=df_L,\n",
    "                x1_F_col = features_F,\n",
    "                x2_F_col = features_F,\n",
    "                x1_G_col = features_G,\n",
    "                x2_G_col = features_G,\n",
    "                y1_col = None,\n",
    "                y2_col = label_col,\n",
    "                batch_size=batch_size_r,\n",
    "                device = DEVICE,\n",
    "                allow_refresh = True\n",
    "            )\n",
    "\n",
    "            data_UU_generator = pairDataGenerator_v2(\n",
    "                df_1=df_U,\n",
    "                df_2=df_U,\n",
    "                x1_F_col = features_F,\n",
    "                x2_F_col = features_F,\n",
    "                x1_G_col = features_G,\n",
    "                x2_G_col = features_G,\n",
    "                y1_col = None,\n",
    "                y2_col = None,\n",
    "                batch_size=batch_size_r,\n",
    "                device = DEVICE,\n",
    "                allow_refresh = True\n",
    "            )\n",
    "             \n",
    "\n",
    "            batch_idx_f = 0\n",
    "            data_L = data_L_generator.get_next()\n",
    "            log_interval_f = 3\n",
    "            \n",
    "            while data_L is not None:\n",
    "                NN.train_mode = 'f'\n",
    "\n",
    "                # ------  Supervised Loss ------ #\n",
    "                x1 = data_L[0].to(DEVICE)\n",
    "                y_true = data_L[1].float().to(DEVICE)\n",
    "                pred_label = NN(x1)\n",
    "                loss_s = F.binary_cross_entropy(pred_label, y_true)\n",
    "\n",
    "                # ====================\n",
    "                # LL :: lambda_LL * g(x_i,x_j) * d (f(x_i),y_j)\n",
    "                # ====================\n",
    "\n",
    "                NN.train_mode = 'f_ll'\n",
    "                x1_y1, x2_y2 = data_LL_generator.get_next()\n",
    "              \n",
    "                x1_F = x1_y1[0]\n",
    "                x1_G = x1_y1[1]\n",
    "                x2_F = x2_y2[0]\n",
    "                x2_G = x2_y2[1]\n",
    "                y1 = x1_y1[2]\n",
    "                y2 = x2_y2[2]\n",
    "               \n",
    "                pred_agreement, pred_y1 = NN([x1_G, x2_G, x1_F])           \n",
    "                loss_LL = regularization_loss(\n",
    "                    pred_agreement, [pred_y1, y2]\n",
    "                )\n",
    "           \n",
    "                # ==================\n",
    "                # UL\n",
    "                # ==================\n",
    "                NN.train_mode = 'f_ul'        \n",
    "                x1_y1, x2_y2 = data_UL_generator.get_next()\n",
    "              \n",
    "                x1_F = x1_y1[0]\n",
    "                x1_G = x1_y1[1]\n",
    "                x2_F = x2_y2[0]\n",
    "                x2_G = x2_y2[1]\n",
    "                y2 = x2_y2[2]\n",
    "\n",
    "                pred_agreement, pred_y1 = NN([x1_G, x2_G, x1_F])\n",
    "                loss_UL = regularization_loss(\n",
    "                    pred_agreement,\n",
    "                    [pred_y1, y2]\n",
    "                )\n",
    "              \n",
    "                # ===================\n",
    "                # UU\n",
    "                # ===================\n",
    "                # print('---- > UU ')\n",
    "                NN.train_mode = 'f_uu'\n",
    "                data_UU = data_UU_generator.get_next()\n",
    "                x1_y1, x2_y2 = data_UL_generator.get_next()\n",
    "                \n",
    "                x1_F = x1_y1[0]\n",
    "                x1_G = x1_y1[1]\n",
    "                x2_F = x2_y2[0]\n",
    "                x2_G = x2_y2[1]\n",
    "                y1 = x1_y1[2]\n",
    "                y2 = x2_y2[2]\n",
    "                \n",
    "                pred_agreement, pred_y1, pred_y2 = NN([x1_G, x2_G, x1_F, x2_F])\n",
    "                loss_UU = regularization_loss(pred_agreement, [pred_y1, pred_y2])\n",
    "              \n",
    "            \n",
    "                # ====================\n",
    "                # Loss\n",
    "                # ====================\n",
    "                loss_total = loss_s + lambda_LL * loss_LL + lambda_UL * loss_UL + lambda_UU * loss_UU\n",
    "                loss_total.backward()\n",
    "                optimizer_f.step()\n",
    "                try:\n",
    "                    data_L = data_L_generator.get_next()\n",
    "                    print(data_L[0].shape)\n",
    "                except Exception:\n",
    "                    data_L = None\n",
    "               \n",
    "                batch_idx_f += 1\n",
    "                if batch_idx_f % log_interval_f == 0:\n",
    "                    print('Batch[f] {} :: Loss {}'.format(batch_idx_f, loss_total))\n",
    "\n",
    "        # ---------------------------\n",
    "        # Self -labelling\n",
    "        # ---------------------------\n",
    "        \n",
    "        data_source_EU = type1_Dataset(\n",
    "            df_U,\n",
    "            x_cols=g_feature_cols,\n",
    "            y_col=None\n",
    "        )\n",
    "        dataLoader_obj_EU = DataLoader(\n",
    "            data_source_EU,\n",
    "            batch_size=512,\n",
    "            shuffle=False,\n",
    "            num_workers=num_proc,\n",
    "            sampler=SequentialSampler(data_source_EU)\n",
    "        )\n",
    "\n",
    "        pred_y_label = []\n",
    "        pred_y_probs = []\n",
    "\n",
    "        NN.train(mode=False)\n",
    "        NN.test_mode = True\n",
    "        NN.train_mode = False\n",
    "        for batch_idx, data_x in enumerate(dataLoader_obj_EU):\n",
    "            data_x = data_x.to(DEVICE)\n",
    "            _pred_y_probs = NN(data_x)\n",
    "            _pred_y_label = torch.argmax(_pred_y_probs, dim=1).cpu().data.numpy()\n",
    "            _pred_y_probs = _pred_y_probs.cpu().data.numpy()\n",
    "            pred_y_label.extend(_pred_y_label)\n",
    "            pred_y_probs.extend(_pred_y_probs)\n",
    "\n",
    "        NN.train(mode=True)\n",
    "        NN.test_mode = False\n",
    "        pred_y_probs = np.array(pred_y_probs)\n",
    "\n",
    "        # ----------------\n",
    "        # Find the top-k most confident label\n",
    "        # Update the set of labelled and unlabelled samples\n",
    "        # ----------------\n",
    "\n",
    "        k = int(len(df_U) * 0.1)\n",
    "        self_labelled_samples = train_utils.find_most_confident_samples(\n",
    "            U_df = df_U.copy(),\n",
    "            y_prob = pred_y_probs,\n",
    "            threshold = 0.4,\n",
    "            max_count=k\n",
    "        )\n",
    "        print(' number of self labelled samples ::', len(self_labelled_samples))\n",
    "\n",
    "        # remove those ids from df_U\n",
    "        rmv_id_list = list(self_labelled_samples[id_col])\n",
    "        df_L = df_L.append(self_labelled_samples, ignore_index=True)\n",
    "        df_U = df_U.loc[~(df_U[id_col].isin(rmv_id_list))]\n",
    "\n",
    "        print(' Len of L and U ', len(df_L), len(df_U))\n",
    "        if len(df_U) < 0.5 * len(df_L):\n",
    "            continue_training = False\n",
    "\n",
    "        # Also check for convergence\n",
    "        current_iter_count += 1\n",
    "        if current_iter_count > max_IC_iter:\n",
    "            continue_training = False\n",
    "        print('----- Validation set ')\n",
    "        train_utils.evaluate_validation(\n",
    "            model = NN,\n",
    "            DEVICE = DEVICE,\n",
    "            data_df = df_L_validation,\n",
    "            x_cols= features_F\n",
    "        )\n",
    "\n",
    "        print('----- Test set ')\n",
    "        train_utils.evaluate_test(\n",
    "            model = NN,\n",
    "            DEVICE = DEVICE,\n",
    "            data_df = df_U_original,\n",
    "            x_cols = features_F\n",
    "        )\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Graph Agreement Module \n",
      "Encoder Layer :: \n",
      " MLP(\n",
      "  (mlp): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): SELU()\n",
      "    (2): Dropout(p=0.05)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): SELU()\n",
      "    (5): Dropout(p=0.05)\n",
      "  )\n",
      ")\n",
      "Predictor Layer :: Linear(in_features=256, out_features=1, bias=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SS_network(\n",
       "  (graph_net): graph_net_v2(\n",
       "    (embedding): Embedding(8940, 128)\n",
       "  )\n",
       "  (agreement_net): agreement_net_v2(\n",
       "    (encoder): MLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (1): SELU()\n",
       "        (2): Dropout(p=0.05)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (4): SELU()\n",
       "        (5): Dropout(p=0.05)\n",
       "      )\n",
       "    )\n",
       "    (predictor_layer): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       "  (clf_net): clf_net_v2(\n",
       "    (mlp): MLP(\n",
       "      (mlp): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.05)\n",
       "        (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.05)\n",
       "        (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "        (7): ReLU()\n",
       "        (8): Dropout(p=0.05)\n",
       "        (9): Linear(in_features=64, out_features=1, bias=True)\n",
       "        (10): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = SS_network(\n",
    "            DEVICE,\n",
    "            node_emb_dimension=node_emb_dim,\n",
    "            num_domains=num_domains,\n",
    "            matrix_pretrained_node_embeddings=matrix_node_emb, # [Number of entities, embedding dimension]\n",
    "            list_gam_encoder_dimensions = gam_encoder_dimensions_mlp,\n",
    "            clf_type = F_classifier_type,    \n",
    "            dict_clf_initilize_inputs = dict_clf_initilize_inputs\n",
    ")\n",
    "\n",
    "NN.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "matrix_node_emb = read_matrix_node_emb(matrix_node_emb_path)\n",
    "node_emb_dim = matrix_node_emb.shape[-1]\n",
    "num_domains = len(domain_dims)\n",
    "\n",
    "# matrix_node_emb = FT(matrix_node_emb).to(DEVICE)\n",
    "matrix_node_emb = FT(matrix_node_emb)\n",
    "\n",
    "if clf_type == 'MLP':\n",
    "    dict_clf_initilize_inputs = {\n",
    "        'mlp_layer_dims' : clf_mlp_layer_dimesnions,\n",
    "        'dropout' : 0.05,\n",
    "        'activation':'relu'\n",
    "    }\n",
    "elif clf_type == 'wide_n_deep':\n",
    "    dict_clf_initilize_inputs = {\n",
    "        'mlp_layer_dims' : clf_mlp_layer_dimesnions,\n",
    "        'dropout' : 0.05,\n",
    "        'activation':'relu'\n",
    "    }\n",
    "elif clf_type == 'deepFM':\n",
    "    dict_clf_initilize_inputs = {\n",
    "        'mlp_layer_dims' : clf_mlp_layer_dimesnions,\n",
    "        'dropout' : 0.05,\n",
    "        'activation':'relu'\n",
    "    }\n",
    "    \n",
    "df_target = train_utils.set_label_in_top_perc( df_target, 10, score_col, true_label_col )\n",
    "train_model( NN, df_target, normal_data_samples_df, features_F, features_G )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Data set lengths : 450 100 4500\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 12.979351997375488\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 9.527286529541016\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 8.659016609191895\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 12.542729377746582\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 12.112624168395996\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 11.679973602294922\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 9.088191986083984\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 9.950020790100098\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 11.24111557006836\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 8.657535552978516\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 12.108551025390625\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 12.540245056152344\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 9.523051261901855\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 13.407291412353516\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 10.387908935546875\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 9.08584213256836\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 9.518478393554688\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 8.653716087341309\n",
      " number of self labelled samples :: 0\n",
      " Len of L and U  450 4500\n",
      "----- Validation set \n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.79\n",
      "Balanced Accuracy  0.5\n",
      "----- Test set \n",
      "Next 10 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5755555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 20 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5277777777777778\n",
      "Balanced Accuracy  0.5\n",
      "Next 30 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.4962962962962963\n",
      "Balanced Accuracy  0.5\n",
      "Next 40 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.5505555555555556\n",
      "Balanced Accuracy  0.5\n",
      "Next 50 % of data ::\n",
      "Precision  0.0\n",
      "Recall  0.0\n",
      "Accuracy  0.6275555555555555\n",
      "Balanced Accuracy  0.5\n",
      "# of parameters to be optimized for g  7\n",
      "# of parameters to be optimized for f  9\n",
      "Training Agreement model .... \n",
      "[[ --- Training Classifier ---- ]]\n",
      "Epoch [f] 0\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 3 :: Loss 7.7994160652160645\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "torch.Size([64, 8])\n",
      "Batch[f] 6 :: Loss 10.817910194396973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-798:\n",
      "Process Process-796:\n",
      "Process Process-809:\n",
      "Process Process-772:\n",
      "Process Process-807:\n",
      "Process Process-799:\n",
      "Process Process-804:\n",
      "Process Process-783:\n",
      "Process Process-810:\n",
      "Process Process-771:\n",
      "Process Process-789:\n",
      "Process Process-790:\n",
      "Process Process-781:\n",
      "Process Process-800:\n",
      "Process Process-778:\n",
      "Process Process-780:\n",
      "Process Process-795:\n",
      "Process Process-777:\n",
      "Process Process-805:\n",
      "Process Process-786:\n",
      "Process Process-776:\n",
      "Process Process-797:\n",
      "Process Process-788:\n",
      "Process Process-785:\n",
      "Process Process-803:\n",
      "Process Process-784:\n",
      "Process Process-779:\n",
      "Process Process-782:\n",
      "Process Process-802:\n",
      "Process Process-773:\n",
      "Process Process-774:\n",
      "Process Process-775:\n",
      "Process Process-806:\n",
      "Process Process-793:\n",
      "Process Process-794:\n",
      "Process Process-801:\n",
      "Process Process-787:\n",
      "Process Process-808:\n",
      "Process Process-791:\n",
      "Process Process-792:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2812, in __getitem__\n",
      "    data = self._take_with_is_copy(indexer, axis=1)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1767, in __getitem__\n",
      "    maybe_callable = com.apply_if_callable(key, self.obj)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2806, in __getitem__\n",
      "    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2806, in __getitem__\n",
      "    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2812, in __getitem__\n",
      "    data = self._take_with_is_copy(indexer, axis=1)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1768, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2806, in __getitem__\n",
      "    indexer = self.loc._get_listlike_indexer(key, axis=1, raise_missing=True)[1]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3409, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1548, in _get_listlike_indexer\n",
      "    keyarr = ax.reindex(keyarr)[0]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1547, in _get_listlike_indexer\n",
      "    indexer = ax.get_indexer_for(key)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3409, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 2123, in _getitem_axis\n",
      "    if com.is_bool_indexer(key):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1548, in _get_listlike_indexer\n",
      "    keyarr = ax.reindex(keyarr)[0]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3395, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 3144, in reindex\n",
      "    target, method=method, limit=limit, tolerance=tolerance\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 4501, in get_indexer_for\n",
      "    return self.get_indexer(target, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3395, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/common.py\", line 127, in is_bool_indexer\n",
      "    if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)) or (\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 3129, in reindex\n",
      "    target = ensure_index(target)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1394, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2716, in get_indexer\n",
      "    if target.is_boolean() and self.is_numeric():\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 2709, in get_indexer\n",
      "    target = ensure_index(target)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\", line 12, in _check\n",
      "    return getattr(inst, attr, \"_typ\") in comp\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1394, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 5357, in ensure_index\n",
      "    return Index(index_like)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1272, in reindex_indexer\n",
      "    return type(self)(new_blocks, new_axes)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 143, in __init__\n",
      "    self._rebuild_blknos_and_blklocs()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 226, in _rebuild_blknos_and_blklocs\n",
      "    if (new_blknos == -1).any():\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1257, in reindex_indexer\n",
      "    new_blocks = self._slice_take_blocks_ax0(indexer, fill_tuple=(fill_value,))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1288, in _slice_take_blocks_ax0\n",
      "    slice_or_indexer, self.shape[0], allow_fill=allow_fill\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 409, in __new__\n",
      "    new_data, dtype=new_dtype, copy=False, name=name, **kwargs\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 295, in __new__\n",
      "    elif is_categorical_dtype(data) or is_categorical_dtype(dtype):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 5357, in ensure_index\n",
      "    return Index(index_like)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 572, in is_categorical_dtype\n",
      "    return CategoricalDtype.is_dtype(arr_or_dtype)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1982, in _preprocess_slice_or_indexer\n",
      "    indexer = np.asanyarray(slice_or_indexer, dtype=np.int64)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/base.py\", line 273, in is_dtype\n",
      "    if isinstance(dtype, (ABCSeries, ABCIndexClass, ABCDataFrame, np.dtype)):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/numpy/core/numeric.py\", line 553, in asanyarray\n",
      "    return array(a, dtype, copy=False, order=order, subok=True)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\", line 12, in _check\n",
      "    return getattr(inst, attr, \"_typ\") in comp\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 1668, in is_boolean\n",
      "    return self.inferred_type in [\"boolean\"]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2812, in __getitem__\n",
      "    data = self._take_with_is_copy(indexer, axis=1)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3409, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3395, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-15-985d94eb52ca>\", line 1, in <module>\n",
      "    train_model( NN, df_target, normal_data_samples_df, features_F, features_G )\n",
      "  File \"<ipython-input-11-9c08bc0e8ec1>\", line 342, in train_model\n",
      "    for batch_idx, data_x in enumerate(dataLoader_obj_EU):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 68361) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "SystemError: <built-in function _error_if_any_worker_fails> returned a result with an error set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/ddatta/Code/AD_v2/AD_v2/src/GAM/torch_data_loader.py\", line 46, in __getitem__\n",
      "    x = self.df[self.x_cols].iloc[idx]\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/frame.py\", line 2812, in __getitem__\n",
      "    data = self._take_with_is_copy(indexer, axis=1)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3409, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis, **kwargs)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/generic.py\", line 3395, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1394, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1257, in reindex_indexer\n",
      "    new_blocks = self._slice_take_blocks_ax0(indexer, fill_tuple=(fill_value,))\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1354, in _slice_take_blocks_ax0\n",
      "    fill_tuple=None,\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/indexes/base.py\", line 391, in __new__\n",
      "    elif is_unsigned_integer_dtype(data.dtype):\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1394, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 932, in is_unsigned_integer_dtype\n",
      "    arr_or_dtype, classes_and_not_datetimelike(np.unsignedinteger)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 1728, in _is_dtype_type\n",
      "    return condition(arr_or_dtype.type)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 217, in <lambda>\n",
      "    issubclass(tipo, klasses)\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 1291, in take_nd\n",
      "    values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1662, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1257, in reindex_indexer\n",
      "    new_blocks = self._slice_take_blocks_ax0(indexer, fill_tuple=(fill_value,))\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/managers.py\", line 1354, in _slice_take_blocks_ax0\n",
      "    fill_tuple=None,\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/internals/blocks.py\", line 1291, in take_nd\n",
      "    values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n",
      "  File \"/home/ddatta/anaconda3/envs/tmp_venv/lib/python3.6/site-packages/pandas/core/algorithms.py\", line 1662, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
